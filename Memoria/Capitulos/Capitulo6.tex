%---------------------------------------------------------------------
%
%                          Capítulo 6
%
%---------------------------------------------------------------------

\chapter{Evaluación}

Al terminar la fase de desarrollo, comenzó la fase de evaluación, cuya finalidad era comprobar la corrección del trabajo realizado y la precisión y alcance de las traducciones, para la cual se usarán métricas y se realizará un análisis cualitativo. En este capítulo se muestra el proceso de dicha evaluación para poder determinar qué tipo de oraciones se logra traducir y con qué nivel de fiabilidad. En la Sección \ref{cap6:sec:Diseño de la evaluación} se explica el diseño de la evaluación realizada, en la Sección \ref{cap6:sec:Resultados de la Evaluación} se presentan los resultados y en la Sección \ref{cap6:sec:Análisis de los Resultados} se realiza el análisis y discusión de los resultados obtenidos.

%-------------------------------------------------------------------
\section{Diseño de la evaluación}
%-------------------------------------------------------------------
\label{cap6:sec:Diseño de la evaluación}

Hemos enfocado la fase de evaluación en la precisión de la traducción a LSE, dejando fuera, por falta de tiempo, aspectos de usabilidad de la aplicación web desarrollada. Para llevar a cabo la evaluación, se creó un corpus de evaluación compuesto por 5 textos, con un total de 137 oraciones. Todas las frases del corpus fueron traducidas a LSE (en formato imagen y vídeo) y fueron enviadas a un experto en LSE para su evaluación.\\

A la hora de seleccionar los textos del corpus de evaluación se tuvieron en cuenta las aplicaciones que podría tener nuestra herramienta de traducción de texto a LSE: traducción de subtítulos, traducción de transcripciones de megafonías de estaciones de tren o aeropuertos, etc. Teniendo en cuenta todo esto, hemos seleccionado como textos para la evaluación las instrucciones de seguridad de un avión, un capítulo de una serie infantil, un anuncio de televisión y un trailer de una película, de los que se reliazó una transcripción manual para obtener todas las oraciones que contenían y que fueron usadas para la evaluación. También se ha añadido un corpus de oraciones sencillas, ya que los otros corpus cuentan con oraciones muy complejas y nuestro traductor se centra en la tradución de oraciones más simples (con estructuras del tipo SUJETO + VERBO + COMPLEMENTOS). A continuación explicamos en detalle los textos seleccionados. \\



\begin{enumerate}
	\item \textbf{Corpus de oraciones de instrucciones de seguridad de un vuelo\footnote{\url{https://www.youtube.com/watch?v=rFohg-glVCU}}:} Este corpus está formado por oraciones complejas que componen los subtítulos de un video real de las instrucciones de seguridad de un avión. Consta de oraciones compuestas con varios verbos y con varios sustantivos, tanto en el sujeto como en el predicado. Está formado por 54 oraciones que podemos observar en el Apéndice \ref{ap1:A}. Algunas de las oraciones que componen este corpus son: 
		
		\begin{itemize}
			\item Les damos la bienvenida a este vuelo de Iberia en nuestro nombre y en el de Madrid.
			\item Antes de despegar tenemos que darles unas instrucciones de seguridad. 
			\item Es importante que presten atención.
		\end{itemize}
	
	\item \textbf{Corpus de oraciones de un capítulo de la serie infantil Peppa Pig\footnote{\url{https://www.youtube.com/watch?v=B1rgTUWqWzI}}:} Corpus compuesto por 34 oraciones simples, en las que se incluyen construcciones específicas del español. En el Apéndice \ref{ap1:B} encontramos las oraciones que componen este corpus. Algunas de estas oraciones son:
	
		\begin{itemize}
			\item Yo soy Pepa.
			\item Este es mi hermano pequeño.
			\item A Pepa le encanta saltar en los charcos.
		\end{itemize}
	
	\item \textbf{Corpus de subtítulos del trailer de la película Togo\footnote{\url{https://www.youtube.com/watch?v=42ubb5bIs9o}}:} Compuesto por 13 oraciones. En este corpus hay oraciones simples con estructura SUJETO + VERBO + OBJETO, y oraciones más complejas que incluyen varios verbos y diversos tipos de complementos. El texto en su totalidad lo podemos encontrar en el Apéndice \ref{ap1:C}. Algunas de estas oraciones son:
	
		\begin{itemize}
			\item Mi negocio son los perros.
			\item Solo un hombre y un perro pueden hacer esa carrera.
			\item Yo siempre pensé que vivía para los trineos.
		\end{itemize}
		
	
	\item \textbf{Corpus de subtítulos de un anuncio de la Covid-19\footnote{\url{https://www.youtube.com/watch?v=oSncDP_vC3Q}}:} Conjunto de 11 oraciones con distintos niveles de complejidad. Hay desde oraciones más simples hasta más complejas con más de un verbo y diversidad de complementos. Algunas de las frases de este corpus cuentan con lenguaje metafórico y oraciones hechas específicas del castellano. El texto que compone este corpus lo encontramos en el Apéndice \ref{ap1:D}. Algunas de las oraciones que lo componen son:
	
		\begin{itemize}
			\item Quédate en casa.
			\item Mantén una distancia de dos metros.
			\item Evita tocar cualquier superficie si es necesario.
		\end{itemize}
	
	\item \textbf{Corpus de oraciones simples:} Conjunto de 25 oraciones, desde oraciones simples con estructura SUJETO + VERBO + COMPLEMENTOS, hasta oraciones a las que se le va añadiendo complejidad con diversos complementos (temporalidad, preposiciones, etc) y varios sustantivos dentro del sujeto. Podemos encontrar todas las oraciones que componen este corpus en el Apéndice \ref{ap1:E}. Algunas de estas oraciones son:
	
		\begin{itemize}
			\item Él bebe agua.
			\item Mis tíos irán al supermercado en coche.
			\item Mi hermana y mi tía están de vacaciones en la playa.
		\end{itemize}
	
\end{enumerate}



%-------------------------------------------------------------------
\section{Resultados de la Evaluación}
%-------------------------------------------------------------------
\label{cap6:sec:Resultados de la Evaluación}

En el Apéndice \ref{ap1:F} pueden verse todas las traducciones de las oraciones del corpus de evaluación en formato imagen, cuya traducción es similar en formato vídeo. Hemos decidido clasificar los resultados en tres grupos: oraciones traducidas correctamente, oraciones cuya traducción no es exacta pero se entiende su significado y oraciones erróneas. En la Tabla \ref{tabla:resultadosCorrectos} se detallan los resultados obtenidos en la evaluación de cada corpus incluyendo únicamente las oraciones traducidas correctamente. La tabla contiene el número de oraciones que componen el corpus, número de oraciones correctas y el porcentaje de aciertos. A continuación, en la tabla \ref{tabla:resultadosNoExactas} se muestra el número de oraciones no traducidas a la perfección, pero cuyo significado se comprende, y el porcentaje que representa. Además, en la tabla \ref{tabla:resultadosEntendibles} se hace referencia a la suma de ambos grupos, mostrando el número y porcentaje de oraciones entendibles, que incluye tanto las oraciones traducidas a la perfección como las no exactas.\\

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Corpus}  & \textbf{Nº oraciones} & \textbf{Nº aciertos} & \textbf{\% acierto}    \\
			\hline \hline
			Instrucciones de avión & 54 & 0 &  0 \%  \\ \hline
			Serie infantil & 34 & 0 & 0 \%   \\ \hline
			Trailer de película & 13 & 0 & 0 \%  \\ \hline
			Anuncio & 11 & 0 & 0 \%   \\ \hline
			Oraciones simples & 25 & 9 & 36 \%  \\ \hline
		\end{tabular}
		\caption{Resultados de la evaluación: traducciones correctas}
		\label{tabla:resultadosCorrectos}
	\end{center}
\end{table}

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|m{4cm}|M{2.1cm}|M{2.3cm}|M{2.1cm}|}
			\hline
			\textbf{Corpus}  & \textbf{Nº oraciones} & \textbf{Nº no exactas} & \textbf{\% no exactas}  \\
			\hline \hline
			Instrucciones de avión & 54 & 0 & 0 \% \\ \hline
			Serie infantil & 34 & 1 & 2.94 \%  \\ \hline
			Trailer de película & 13 & 2 & 15.38 \%  \\ \hline
			Anuncio & 11 & 0 & 0 \%  \\ \hline
			Oraciones simples & 25 & 6 & 24 \%  \\ \hline
		\end{tabular}
		\caption{Resultados de la evaluación: traducciones no exactas}
		\label{tabla:resultadosNoExactas}
	\end{center}
\end{table}

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|m{4cm}|M{2.1cm}|M{2.3cm}|M{2.1cm}|}
			\hline
			\textbf{Corpus}  & \textbf{Nº oraciones} & \textbf{Nº entendibles} & \textbf{\% entendible}  \\
			\hline \hline
			Instrucciones de avión & 54 & 0 &  0 \% \\ \hline
			Serie infantil & 34 & 1 &  2.94 \%  \\ \hline
			Trailer de película & 13 & 2 & 15.38 \%  \\ \hline
			Anuncio & 11 & 0 &  0 \%  \\ \hline
			Oraciones simples & 25 & 15 & 60 \%  \\ \hline
		\end{tabular}
		\caption{Resultados de la evaluación: traducciones entendibles}
		\label{tabla:resultadosEntendibles}
	\end{center}
\end{table}

Como podemos observar en estos resultados, el corpus de oraciones sencillas cuenta con un porcentaje de traducciones entendibles bastante alto (60\%), mientras que el resto de corpus cuentan con mayor margen de mejora. Esto es debido a que en estos últimos la complejidad de las oraciones es más elevada, produciendo así una serie de errores que analizaremos en la sección \ref{cap6:sec:Análisis de los Resultados}. En esta sección también veremos que una parte importante de las traducciones erróneas se debe a la falta de imágenes o vídeos LSE, ya que más del 33\% de los signos que se buscan en la biblioteca no se encuentran.


%-------------------------------------------------------------------
\section{Análisis de los Resultados}
%-------------------------------------------------------------------
\label{cap6:sec:Análisis de los Resultados}

En este apartado se han analizado los resultados en las oraciones que no se han traducido a la perfección (traducciones erróneas y traducciones no exactas), agrupándolas según el tipo de error que se ha obtenido. De cada una de estas oraciones únicamente se ha extraído el error más grave, ya que el resto de errores (si los hubiera), podrían haber sido provocados por este. Por ejemplo, la traducción que proporciona Text2LSE de \textit{``Yo bebo agua''} es \textit{``YO BEBO AGUA''}, cuando debería ser \textit{``YO AGUA BEBER''}. Esto se debe a un fallo del analizador, que no reconoce la palabra \textit{``bebo''} como verbo, lo que además provoca que no se encuentre el recurso para ese signo. Por ello, esta frase está únicamente en la categoría \textit{``Fallo del analizador Spacy''}, y no en  \textit{``Falta de imágenes o vídeos LSE''}. Para realizar la clasificación se han analizado las traducciones en formato imagen, ya que el resultado es similar al formato vídeo, y se ha revisado tanto los signos como el texto que los acompaña con el fin de determinar de qué tipo de error se trata. Para el resto de casos hemos agrupado los resultados dependiendo del tipo de error obtenido. En la Tabla \ref{tabla:analisisResultados} podemos observar el número de fallos de cada tipo y su porcentaje de error.

\begin{itemize}
	
	\item \textbf{Género y número:} El sistema si no encuentra el signo de un sustantivo busca esa palabra sin morfemas de género y número, y si así encuentra el signo se añade a continuación los signos \textit{``FEMENINO''} y \textit{``PLURAL''} en caso de que el sustantivo fuese femenino y plural. Pero hay ocasiones en las que no haría falta añadirlo. Por ejemplo, en la oración \textit{``y disponen de rampas o balsas de evacuación''} se traduce \textit{``rampas''} como \textit{``RAMPA FEMENINO PLURAL''}, pero en este caso al ser la palabra \textit{``rampa''} femenino no haría falta añadir el signo \textit{``FEMENINO''}.
	
	\item \textbf{Cambio de significado:} El significado de la oración ha cambiado al realizar la traducción a LSE. Por ejemplo, la oración \textit{``Mi negocio son los perros''} se traduce como \textit{``YO NEGOCIO PERRO PLURAL''}. Sin embargo, en este caso la traducción correcta sería \textit{``YO NEGOCIO PERRO''}, ya que el signo \textit{``PLURAL''} se entiende en referencia a negocio y no a perro, por lo que el significado de la traducción cambia a que su negocio son los perros y otros negocios más.	
		
	\item \textbf{Preposiciones:} La aplicación no tiene en cuenta todas las particularidades de las preposiciones en la LSE. Por ejemplo, al traducir la oración \textit{``Le ganó a todos los demás''}  se elimina la preposición \textit{``a''}, obteniendo \textit{``PASADO DEMÁS TODOS GANAR''}. Según las normas de la LSE dicha preposición sí debería de aparecer en la traducción final, ya que eliminarla cambia el sentido de la traducción a \textit{``Todos los demás ganaron''}.
	
	\item \textbf{Negación:} Text2LSE no ha contemplado el orden de aparición de la negación en una oración. Por eso en oraciones, como por ejemplo, \textit{``Él no es un perro de trineo''} realiza la traducción \textit{``ÉL PERRO NO TRINEO''}, cuando debería ser \textit{``ÉL PERRO TRINEO NO''}, ya que en LSE la negación se coloca al final de la oración.
	
	\item \textbf{Particularidad LSE:} En LSE existen frases hechas que se dicen con un único signo concreto, por lo que es incorrecto realizar la traducción de la frase hecha palabra por palabra. Por ejemplo, la oración \textit{``Por favor''} es una oración hecha y en LSE se traduce como un solo signo, como podemos ver en la Figura~\ref{fig: imgPorfavor}.
	
	\begin{figure}[]
		\centering
		\includegraphics[width=0.5\textwidth]{Imagenes/Fuentes/Text2LSE/porfavor.jpg}
		\caption[Representación del signo ``por favor'' en LSE]{Representación del signo ``por favor'' en LSE \footnote{\url{http://www.fundacioncnse.org}}}
		\label {fig: imgPorfavor}
	\end{figure}
	\footnotetext{\url{http://www.fundacioncnse.org}}
	
	\item \textbf{Estructuras compuestas:} En esta primera versión de Text2LSE no se han tenido en cuenta en el desarrollo las estructuras más complejas, como pueden ser verbos compuestos, pasados perfectos u oraciones compuestas con varios verbos. Esto se puede observar en la oración \textit{``Pepa ha encontrado un charco pequeño''} cuya traducción proporcionada por la aplicación es \textit{``PASADO PEPA HA CHARCO PEQUEÑO ENCONTRAR''}. En este caso, al no tener en cuenta la aparición de un verbo compuesto, la traducción es errónea, ya que se debería eliminar la palabra \textit{``HA''}.
	
	\item \textbf{Polisemia:} El sistema no tiene en cuenta la polisemia de las palabras, es decir, que una misma palabra pueda tener varios significados, por lo que en la traducción en estos casos se pueden mostrar signos que correspondan a un significado que no es el adecuado para la frase. Por ejemplo, en la oración \textit{``Encontraron la cura''} el signo \textit{``CURA''} buscado debe ser el de cura referente a sanación, y no el de \textit{``CURA''} referente a sacerdote.
	
	\item \textbf{Fallo del analizador Spacy:} Text2LSE ha utilizado el analizador Spacy, el cual no tiene un porcentaje de acierto del 100\%. Por tanto, puede haber ocasiones en que el análisis realizado por Spacy no sea correcto y esto lleve a nuestro sistema a fallar en la traducción. Esto lo podemos comprobar en oraciones como \textit{``Solo es barro''}, en la que Spacy nos dice que  \textit{``barro''} es un sustantivo cuando en realidad es un verbo (\textit{``barrer''}), lo que hace que nuestro sistema traduzca la frase como \textit{``SOLO BARRER''}, que es incorrecta.
	
	\item \textbf{Falta de imágenes o vídeos LSE:} Para realizar las traducciones se han utilizado los recursos LSE de ARASAAC, los cuales no incluyen signos para todas las palabras del castellano. Por ejemplo, al traducir la frase \textit{``El corazón de un superviviente''}, vemos que la traduccion que hace nuestro sistema a LSE (\textit{``CORAZÓN SUPERVIVIENTE''}) es correcta, sin embargo, el catálogo de recursos LSE de ARASAAC no incluye el signo para la palabra \textit{``SUPERVIVIENTE''}, por lo que la traducción a vídeo o imagen que realiza nuestra aplicación deja una imagen o vídeo de error para esa palabra, quedando la traducción incompleta.
	
	\item \textbf{Nombres propios:} En la LS no existen signos para los nombres propios, sino que estos se deletrean. En el desarrollo de la aplicación no se han tenido en cuenta los nombres propios, por lo que Text2LSE muestra una imagen o vídeo de error cuando se encuentra con uno.
		
	
	
	
\end{itemize}
		
		
 Como podemos observar en la Tabla \ref{tabla:analisisResultados}, las oraciones con un margen de mejora más amplio son las que contienen estructuras compuestas, que suponen un 32\% del total de errores obtenidos. Esto se debe a que en el desarrollo de la aplicación nos hemos centrado en la traducción de oraciones con estructuras simples como primera aproximación al problema planteado. Otro aspecto a mejorar serían las particularidades de la LSE, cuya solución sería introducir reglas concretas en el código para tratar todas estas particularidades de forma correcta. A pesar de estos errores en las traducciones, los resultados de la evaluación han sido muy satisfactorios. Teniendo en cuenta que actualmente no existe ninguna aplicación capaz de traducir castellano a LSE en tiempo real. Text2LSE en un futuro puede ser de gran ayuda para el colectivo de personas sordas, ya que actualmente traduce un número de oraciones considerable, que fácilmente se puede ampliar trabajando en los problemas anteriormente mencionados. \\

\begin{table}[htbp]
	\begin{center}
		\begin{tabular}{|m{5.5cm}|M{2.5cm}|M{2.5cm}|}
			\hline
			\textbf{Tipos de fallos}  & \textbf{Nº fallos / Total fallos} & \textbf{\% fallos}  \\
			\hline \hline
			Estructuras compuestas	  					& 42 / 129 	&  32.55 \%  \\ \hline
			Particularidad LSE  						& 35 / 129 	&  27.13 \%  \\ \hline
			Fallo del analizador	  					& 21 / 129 	&  16.27 \%  \\ \hline
			Falta de imágenes o vídeos LSE 	  		    & 11 / 129 	&  8.52 \%  \\ \hline
			Preposiciones  								& 8 / 129	&  6.20 \%  \\ \hline
			Nombres propios	  					    	& 4 / 129 	&  3.10 \%  \\ \hline
			Negación	  								& 3 / 129 	&  2.32 \%  \\ \hline
			Género y número 							& 2 / 129 	&  1.55 \%  \\ \hline
			Cambio de significado  						& 2 / 129 	&  1.55 \%  \\ \hline
			Polisemia								  	& 1 / 129 	&  0.77 \%  \\ \hline				
			
		\end{tabular}
		\caption{Oraciones traducidas incorrectamente por cada tipo de error}
		\label{tabla:analisisResultados}
	\end{center}
\end{table}


Como hemos visto, la falta de imágenes y vídeos para muchas palabras del corpus de evaluación hace que el porcentaje de acierto de nuestro sistema sea muy bajo. Por ello, creemos que es interesante realizar también una evaluación de la precisión de la traducción a texto LSE de nuestro sistema. En la Tabla \ref{tabla:resultadosCorrectosText} se muestran las traducciones perfectas y su porcentaje con respecto al número  total de frases por corpus. La Tabla \ref{tabla:resultadosNoExactasText} de la misma manera refleja las traducciones que se entienden pero no son perfectas, y finalmente en la Tabla \ref{tabla:resultadosEntendiblesText} se pueden observar los resultados en cuanto a traducciones entendibles (suma de perfectas y no exactas) siguiendo este mismo criterio.\\

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Corpus}  & \textbf{Nº oraciones} & \textbf{Nº aciertos} & \textbf{\% acierto}    \\
			\hline \hline
			Instrucciones de avión & 54 & 7 &  12.96 \%  \\ \hline
			Serie infantil & 34 & 4 & 11.76 \%   \\ \hline
			Trailer de película & 13 & 1 & 7.69 \%  \\ \hline
			Anuncio & 11 & 1 & 9.09 \%   \\ \hline
			Oraciones simples & 25 & 11 & 44 \%  \\ \hline
		\end{tabular}
		\caption{Resultados de la evaluación: traducciones correctas en texto LSE}
		\label{tabla:resultadosCorrectosText}
	\end{center}
\end{table}

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|m{4cm}|M{2.1cm}|M{2.3cm}|M{2.1cm}|}
			\hline
			\textbf{Corpus}  & \textbf{Nº oraciones} & \textbf{Nº no exactas} & \textbf{\% no exactas}  \\
			\hline \hline
			Instrucciones de avión & 54 & 14 & 25.92 \% \\ \hline
			Serie infantil & 34 & 7 & 20.58 \%  \\ \hline
			Trailer de película & 13 & 3 & 23.07 \%  \\ \hline
			Anuncio & 11 & 2 & 18.18 \%  \\ \hline
			Oraciones simples & 25 & 8 & 32\%  \\ \hline
		\end{tabular}
		\caption{Resultados de la evaluación: traducciones no exactas en texto LSE}
		\label{tabla:resultadosNoExactasText}
	\end{center}
\end{table}

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|m{4cm}|M{2.1cm}|M{2.3cm}|M{2.1cm}|}
			\hline
			\textbf{Corpus}  & \textbf{Nº oraciones} & \textbf{Nº entendibles} & \textbf{\% entendible}  \\
			\hline \hline
			Instrucciones de avión & 54 & 21 &  38.88\% \\ \hline
			Serie infantil & 34 & 11 &  28.94\%  \\ \hline
			Trailer de película & 13 & 4 & 30.76 \%  \\ \hline
			Anuncio & 11 & 3 &  27.27\%  \\ \hline
			Oraciones simples & 25 & 19 & 76\%  \\ \hline
		\end{tabular}
		\caption{Resultados de la evaluación: traducciones entendibles en texto LSE}
		\label{tabla:resultadosEntendiblesText}
	\end{center}
\end{table}



Como podemos observar en estos resultados, el corpus de oraciones sencillas cuenta con un porcentaje de traducciones entendibles bastante más alto (76\%) que el resto de corpus, cuyos porcentajes rondan el 20 o el 30\%. Esto es debido a que en estos últimos la complejidad y riqueza de vocabulario de las oraciones es más elevada. En comparación con los resultados globales, llegamos a la conclusión de que añadiendo más recursos a la biblioteca de recursos LSE de ARASAAC, los porcentajes de éxito aumentan de manera notable, por lo que merece la pena trabajar en este sentido.\\


Por otro lado, se han analizado todas las traducciones que cuyo texto LSE es entendible, haciendo un recuento de los signos que se buscan y viendo qué porcentaje de signos no se encuentran en el catálogo de ARASAAC, con el fin de dar una idea de qué parte de fallos son debidos a la falta de signos en el catálogo. En la tabla \ref{tabla:resultadoSignos} se muestra el número de signos buscados en el catálogo de ARASAAC, el número de signos que no se encuentran y el porcentaje que este representa.\\

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|m{4cm}|M{2.1cm}|M{2.3cm}|M{2.1cm}|}
			\hline
			\textbf{Corpus}  & \textbf{Nº signos buscados} & \textbf{Nº signos no encontrados}  & \textbf{\% error}  \\
			\hline \hline
			Instrucciones de avión & 101 & 53 &  52.47\% \\ \hline
			Serie infantil & 44 & 17 & 38.63\%  \\ \hline
			Trailer de película & 14 & 5 & 35.71\%  \\ \hline
			Anuncio & 14 & 5 & 35.71\%  \\ \hline
			Oraciones simples & 86 & 7 & 8.13\%  \\ \hline
		\end{tabular}
		\caption{Resultados de la evaluación: signos buscados y signos no encontrados}
		\label{tabla:resultadoSignos}
	\end{center}
\end{table}

Como podemos observar en la Tabla \ref{tabla:resultadoSignos}, la cantidad de signos que se buscan pero no están en el catálogo representan un porcentaje considerable del total, llegando incluso a ser más de la mitad en el caso del corpus de instrucciones de avión y superando el 33\% en el conjunto de todos los corpus. Esto quiere decir que oraciones que Text2LSE es capaz de traducir correctamente acaban siendo erróneas por culpa de un catálogo insuficiente, lo que refuerza la conclusión de que merece la pena trabajar en añadir más recursos al catálogo actual.
